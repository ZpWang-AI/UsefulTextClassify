[['base', True], ['batch_size', 8], ['clip', False], ['cuda_id', '8'], ['dev_data_file', ''], ['device', 'cuda'], ['epochs', 10], ['input_feature', 'reply only'], ['just_test', False], ['lr', 5e-05], ['model_name', 'hfl/chinese-roberta-wwm-ext'], ['pb_frequency', 20], ['pretrained_model_fold', './saved_model'], ['save_model_epoch', 1], ['save_res_fold', './saved_res'], ['train_data_file', './data/2_result.xlsx'], ['train_ratio', 0.8], ['version', 'train 2 test 2']]
2023-03-20_13:30:41
=== start training ===
batch[20/100], loss: 0.411370
batch[40/100], loss: 0.338329
batch[60/100], loss: 0.327375
batch[80/100], loss: 0.334647
batch[100/100], loss: 0.328703
epoch1 ends
f1       : 71.91%
accuracy : 87.50%
precision: 91.43%
recall   : 59.26%

	 pred_0	 pred_1
gt_0 	 143 	 3
gt_1 	 22 	 32
batch[20/100], loss: 0.161377
batch[40/100], loss: 0.184556
batch[60/100], loss: 0.186166
batch[80/100], loss: 0.185068
batch[100/100], loss: 0.174560
epoch2 ends
f1       : 77.69%
accuracy : 86.50%
precision: 70.15%
recall   : 87.04%

	 pred_0	 pred_1
gt_0 	 126 	 20
gt_1 	 7 	 47
batch[20/100], loss: 0.122002
batch[40/100], loss: 0.098120
batch[60/100], loss: 0.101825
batch[80/100], loss: 0.101614
batch[100/100], loss: 0.101797
epoch3 ends
f1       : 72.00%
accuracy : 86.00%
precision: 78.26%
recall   : 66.67%

	 pred_0	 pred_1
gt_0 	 136 	 10
gt_1 	 18 	 36
batch[20/100], loss: 0.092509
batch[40/100], loss: 0.097057
batch[60/100], loss: 0.097238
batch[80/100], loss: 0.095122
batch[100/100], loss: 0.096916
epoch4 ends
f1       : 72.73%
accuracy : 86.50%
precision: 80.00%
recall   : 66.67%

	 pred_0	 pred_1
gt_0 	 137 	 9
gt_1 	 18 	 36
batch[20/100], loss: 0.052522
batch[40/100], loss: 0.031483
batch[60/100], loss: 0.024228
batch[80/100], loss: 0.019032
batch[100/100], loss: 0.018204
epoch5 ends
f1       : 70.97%
accuracy : 86.50%
precision: 84.62%
recall   : 61.11%

	 pred_0	 pred_1
gt_0 	 140 	 6
gt_1 	 21 	 33
batch[20/100], loss: 0.020199
batch[40/100], loss: 0.037813
batch[60/100], loss: 0.043314
batch[80/100], loss: 0.047651
batch[100/100], loss: 0.048140
epoch6 ends
f1       : 69.90%
accuracy : 84.50%
precision: 73.47%
recall   : 66.67%

	 pred_0	 pred_1
gt_0 	 133 	 13
gt_1 	 18 	 36
batch[20/100], loss: 0.008562
batch[40/100], loss: 0.014406
batch[60/100], loss: 0.023446
batch[80/100], loss: 0.034314
batch[100/100], loss: 0.035731
epoch7 ends
f1       : 72.92%
accuracy : 87.00%
precision: 83.33%
recall   : 64.81%

	 pred_0	 pred_1
gt_0 	 139 	 7
gt_1 	 19 	 35
batch[20/100], loss: 0.033639
batch[40/100], loss: 0.056076
batch[60/100], loss: 0.051025
batch[80/100], loss: 0.048041
batch[100/100], loss: 0.040417
epoch8 ends
f1       : 75.93%
accuracy : 87.00%
precision: 75.93%
recall   : 75.93%

	 pred_0	 pred_1
gt_0 	 133 	 13
gt_1 	 13 	 41
batch[20/100], loss: 0.004387
batch[40/100], loss: 0.002826
batch[60/100], loss: 0.014013
batch[80/100], loss: 0.012975
batch[100/100], loss: 0.010854
epoch9 ends
f1       : 78.18%
accuracy : 88.00%
precision: 76.79%
recall   : 79.63%

	 pred_0	 pred_1
gt_0 	 133 	 13
gt_1 	 11 	 43
batch[20/100], loss: 0.001947
batch[40/100], loss: 0.001492
batch[60/100], loss: 0.005580
batch[80/100], loss: 0.005039
batch[100/100], loss: 0.010059
epoch10 ends
f1       : 73.04%
accuracy : 84.50%
precision: 68.85%
recall   : 77.78%

	 pred_0	 pred_1
gt_0 	 127 	 19
gt_1 	 12 	 42
=== finish training ===
2023-03-20_13:33:05
